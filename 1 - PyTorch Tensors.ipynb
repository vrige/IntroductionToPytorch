{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First, we'll import pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's see a few basic tensor manipulations. First, just a few of the ways to create tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "z = torch.zeros(5, 3)\n",
    "print(z)\n",
    "print(z.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Above, we create a 5x3 matrix filled with zeros, and query its datatype to find out that the zeros are 32-bit floating point numbers, which is the default PyTorch.\n",
    "\n",
    "What if you wanted integers instead? You can always override the default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "i = torch.ones((5, 3), dtype=torch.int16)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can see that when we do change the default, the tensor helpfully reports this when printed.\n",
    "\n",
    "It's common to initialize learning weights randomly, often with a specific seed for the PRNG for reproducibility of results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A random tensor:\n",
      "tensor([[0.3126, 0.3791],\n",
      "        [0.3087, 0.0736]])\n",
      "\n",
      "A different random tensor:\n",
      "tensor([[0.4216, 0.0691],\n",
      "        [0.2332, 0.4047]])\n",
      "\n",
      "Should match r1:\n",
      "tensor([[0.3126, 0.3791],\n",
      "        [0.3087, 0.0736]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1729)\n",
    "r1 = torch.rand(2, 2)\n",
    "print('A random tensor:')\n",
    "print(r1)\n",
    "\n",
    "r2 = torch.rand(2, 2)\n",
    "print('\\nA different random tensor:')\n",
    "print(r2) # new values\n",
    "\n",
    "torch.manual_seed(1729)\n",
    "r3 = torch.rand(2, 2)\n",
    "print('\\nShould match r1:')\n",
    "print(r3) # repeats values of r1 because of re-seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "PyTorch tensors perform arithmetic operations intuitively. Tensors of similar shapes may be added, multiplied, etc. Operations with scalars are distributed over the tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.]])\n",
      "torch.Size([2, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 13\u001B[0m\n\u001B[0;32m     11\u001B[0m r1 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrand(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m     12\u001B[0m r2 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrand(\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m---> 13\u001B[0m r3 \u001B[38;5;241m=\u001B[39m \u001B[43mr1\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mr2\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "ones = torch.ones(2, 3)\n",
    "print(ones)\n",
    "\n",
    "twos = torch.ones(2, 3) * 2 # every element is multiplied by 2\n",
    "print(twos)\n",
    "\n",
    "threes = ones + twos       # additon allowed because shapes are similar\n",
    "print(threes)              # tensors are added element-wise\n",
    "print(threes.shape)        # this has the same dimensions as input tensors\n",
    "\n",
    "r1 = torch.rand(2, 3)\n",
    "r2 = torch.rand(3, 2)\n",
    "r3 = r1 + r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here's a small sample of the mathematical operations available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A random matrix, r:\n",
      "tensor([[-0.0022, -0.6116],\n",
      "        [-0.3071, -0.8297]])\n",
      "\n",
      "Absolute value of r:\n",
      "tensor([[0.0022, 0.6116],\n",
      "        [0.3071, 0.8297]])\n",
      "\n",
      "Inverse sine of r:\n",
      "tensor([[-0.0022, -0.6581],\n",
      "        [-0.3122, -0.9785]])\n",
      "\n",
      "Determinant of r:\n",
      "tensor(-0.1860)\n",
      "\n",
      "Singular value decomposition of r:\n",
      "torch.return_types.svd(\n",
      "U=tensor([[-0.5599, -0.8286],\n",
      "        [-0.8286,  0.5599]]),\n",
      "S=tensor([1.0611, 0.1753]),\n",
      "V=tensor([[ 0.2410, -0.9705],\n",
      "        [ 0.9705,  0.2410]]))\n",
      "\n",
      "Average and standard deviation of r:\n",
      "(tensor(0.3608), tensor(-0.4376))\n",
      "\n",
      "Maximum value of r:\n",
      "tensor(-0.0022)\n"
     ]
    }
   ],
   "source": [
    "r = torch.rand(2, 2) - 0.5 * 2 # values between -1 and 1\n",
    "print('A random matrix, r:')\n",
    "print(r)\n",
    "\n",
    "# Common mathematical operations are supported:\n",
    "print('\\nAbsolute value of r:')\n",
    "print(torch.abs(r))\n",
    "\n",
    "# ...as are trigonometric functions:\n",
    "print('\\nInverse sine of r:')\n",
    "print(torch.asin(r))\n",
    "\n",
    "# ...and linear algebra operations like determinant and singular value decomposition\n",
    "print('\\nDeterminant of r:')\n",
    "print(torch.det(r))\n",
    "print('\\nSingular value decomposition of r:')\n",
    "print(torch.svd(r))\n",
    "\n",
    "# ...and statistical and aggregate operations:\n",
    "print('\\nAverage and standard deviation of r:')\n",
    "print(torch.std_mean(r))\n",
    "print('\\nMaximum value of r:')\n",
    "print(torch.max(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "There's a good deal more to know about the power of PyTorch tensors, including how to set them up for parallel computations on GPU - we'll be going into more depth in another video."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}